{
  /* Разбирает параметры командной строки и запускает демон. Опций не имеет.*/
  "startup": {},

  /*****************************************************************/
  /* Читает и валидирует файл конфигурации.                        */
  /*****************************************************************/
  "config": {
    "enabled": true,
    /* Разрешить перечитывать конфигурацию по сигналу SIGHUP */
    "reload_sighup": false,
    /* Проверять на изменения конфигурацию и перечитывать ее. 0 - выкл.*/
    "reload_changed_ms": 0
    /* Примечание: Динамическое переконфигурирование работает крайне нестабильно, поэтому использовать в бою нельзя */
  },

  /*****************************************************************/
  /* Ядро WFC. Реализует алгоритмы инициализации и запуска системы */
  /*****************************************************************/
  "core": {
    /* Периодичность выполнения задач ядра (проверка на переинициализации при изменении конфигурации или флаг выхода)*/
    "core_timeout_ms": 1000,
    /* Запуск пользовательских задач в основном потоке демона */
    "idle_timeout_ms": 1000,
    /* Ограничение оперативной памяти */
    "rlimit_as_mb": 0,
    /* Зарезервировано (пока не работает)*/
    "enable_callback_check": true,

    /*Настройка workflow ядра */
    "core-workflow": {
      /* Число рабочих потоков. 0 - в основном потоке демона */
      "threads": 2,
      /* Использовать boost::io_service */
      "use_io_service": true

      /* Примечание: workflow - это очередь задач и пул потоков, который ее разгребает.
       *             Также поддерживает таймеры и реквестеры. Каждый прикладной объект 
       *             имеет доступ к workflow, если он не указан, то используется этот
       *             workflow ядра. См. также раздел "workflow"
       */
    },
    /* список ядер cpu для потоков WFC (потоки workflow, серверов и клиентов, а также пользовательских зарегистрированных потоков) */
    "cpu": [ ],
    /* список ядер cpu для всех остальных потоков */
    "unreg-cpu": []
  },

    /*****************************************************************/
  /* Система логирования                                           */
  /*****************************************************************/
  "logger": {
    /* При отключении модуля логирования сообщения выводятся в clog без форматирования */
    "enabled": true,
    /* Приоритет запуска. Должен быть минимальным в конфигурации, чтобы логирование запускалось раньше всех */
    "startup_priority": -1000,
    /* Аналогично, останов логирования должен происходить в последнюю очередь */
    "shutdown_priority": 1000,
    /* Отображать миллисекунды в логах */
    "milliseconds": true,
    /* Ограничение длинны лог-файла в байтах */
    "limit": 10000000,
    /* Стандартный вывод в режиме не-демона: cerr, cout или clog */
    "stdout": "clog",
    /* Путь для файла(ов) логов. В сингл режиме просто добавляется ".log" */
    "path": "/logs/prefixdb-slave1",
    /* Разрешить писать в syslog (имя) */
    "syslog": "",
    /* Список запрещенных логов или типов логов в нижнем регистре */
    "deny": ["debug"],
    /* Если false то каждый лог пишется в отдельный файл, например /logs/dartc.domain.log */
    "single": true,
    "custom": {
      /* Карта кастомных настроек для каждого лога, например можно лог stat писать в отдельный файл */
      "stat":{
        "path": "/logs/prefixdb-slave1-stat.log",
        "milliseconds": true
      }
    }
  },

  /*****************************************************************/
  /* Рабочие процессы                                              */
  /*****************************************************************/
  "workflow": [
    {
      /* workflow обработки jsonrpc-запросов (см. jsonrpc-queue) */
      "name": "server-workflow",
      "enabled": true,
      /* запускаем раньше, чем server-tcp, чтобы очередь не разбухала */
      "startup_priority": -900,
      "shutdown_priority": 900,
      /* Максимальный размер очереди (для jsonrpc в штатном режиме 1-2, разрастание очереди свидетельствует о том, что сервер не справляется) 
       * При запуске возможен кратковременное разрастание когда одновременно приходит множество запросов */
      "maxsize": 100,
      /* Размер очереди при котором происходить предупреждение в лог */
      "wrnsize": 10,
      /* Периодичность записи предупреждения в лог (пока размер превосходит wrnsize) */
      "show_wrn_ms": 1000,
      /* Число рабочих потоков. 0 - в основном потоке демона */
      "threads": 1,
      "use_io_service": true,
      /* Обрабатывать задачи с задержкой. Например для 50 мс, означает что время ответа на запрос будет не менее 50мс. 
       * Можно открыть отдельный порт для кроновых скриптов и настроить очередь с задержкой, чтобы не сильно "валили" запросами */
      "post_delay_ms": 0,
      /* Ограничение по количеству обрабатываем задач ОДНИМ потоком. */
      "rate_limit": 0,
      /* Список выделенных ядер CPU для потоков этого workflow. Если пуст, то настройки ядра  WFC */
      "cpu": []
    },
    
    /* Для prefixdb*/
    {
      "name": "prefixdb-workflow",
      "enabled": true,
      "startup_priority": -900,
      "shutdown_priority": 900,
      "maxsize": 1000,
      "wrnsize": 100,
      "show_wrn_ms": 1000,
      "threads": 1,
      "use_io_service": true,
      "post_delay_ms": 0,
      "rate_limit": 0,
      "cpu": []
    }
  ],

  /*****************************************************************/
  /* TCP сервер                                                    */
  /*****************************************************************/
  "server-tcp": [
    {
      "name": "server-tcp",
      "enabled": true,
      /* В режиме suspend работает как эхо-сервер */
      "suspend": false,
      /* Порты открываем в последнюю очередь */
      "startup_priority": 1000,
      /* А закрываем в первую, чтобы входящий поток запросов не мешал корректно завершить работу */
      "shutdown_priority": -1000,
      /* Здесь используется свой пул запросов, workflow только для таймеров, можно использовать workflow ядра */
      "workflow": "",
      /* Следующий по цепочке компонент сбора io-статистики, для мониторинга входящего трафика */
      "target": "server-queue",
      /* Включает поддержку keep-alive */
      "keep-alive": true,
      /* Список выделенных ядер CPU для потоков этого сервера. Если пуст, то настройки ядра WFC */
      "cpu": [],

      /* Количество потоков.
       * В каждом потоке "висит" акцептор и в нем же обрабатываются сокеты, которые принял акцептор.
       * Если используется входящая очередь ( io-queue из пакета wfc_io или jsonrpc-queue из пакета wfc_jsonrpc)
       * то нет смысла запускать большое количество потоков, с парсингом и сборкой по простому разделителю сервер 
       * справляется достаточно эффективно.
       * Если время ответа от прикладной логики стабильно мало (более 100000 запросов в сек. ( или менее 10 мкс) ) 
       * то имеет смысл отключить очереди и увеличить количество потоков сервера. На общее время ответа это не сильно 
       * повлияет, но заметно снизит нагрузку на CPU.
       * Архитектура "один слушатель" + "пул воркеров" не поддерживается, т.к. по производительности и ресурсам 
       * она не превосходит схему сервер+очередь, но имеет те же недостатки варианта сервер без очереди (при тяжелом 
       * запросе остальные сокеты потока вынуждены ждать 
       */
      "threads": 1,
      /*ip адрес или имя хоста*/
      "addr": "0.0.0.0",
      "port": "23500",
      /* Очередь входящих запросов на соединение (linux) */
      "backlog": 1024,
      /* Ограничение на количество одновременных подключений (сервер)*/
      "max_connections": 0,

      /* настройки для коннектов */
      "connection": {
        /* 'Читатель' из сокета */
        "reader": {
          /* разделитель входного потока*/
          "sep": "\r\n",
          /* Буфер для операции чтения. Можно уменьшить, если все запросы короткие, 
           * но нет смысла увеличивать больше 8-32Кб даже для больших запросов или 
           * потока сообщений по одному подключению */
          "bufsize": 4096,
          /* Максимальный размер чанка входящего буфера, после которого происходит разделение на массивы размером не более bufsize */
          "maxbuf": 8192,
          /* Если при разделении, последний буфер меньше minbuf то он сливается с предпоследним, при условии, что не будет превышен maxbuf*/ 
          "minbuf": 0,
          /* Удалять разделитель из сообщения*/
          "trimsep": true
        },
        /* 'Писатель' в сокет */
        "writer": {
          /* Добавляет разделитель в конец сообщения */
          "sep": "\r\n",
          /* Буфер для операции записи. */
          "bufsize": 8192,
          /* Максимальный размер чанка исходящего буфера, после которого происходит разделение на массивы размером не более bufsize */
          "maxbuf": 8192,
          /* Если при разделении, последний буфер меньше minbuf то он сливается с предпоследним, при условии, что не будет превышен maxbuf*/ 
          "minbuf": 0,
          /* Если исходящий буфер пуст, а размер сообщения превышает maxbuf, то делается попытка записать сообщение целиком 
             и только потом остаток сообщения разбивается на чанки размером bufsize. Эффективно работает на сообщениях до 1Мб, если больше
             то эффективнее предварительно разбить на массивы 16-32Кб   */
          "first_as_is": true
        }
      }
    }
  ],

  /*****************************************************************/
  /* Очередь jsonrpc-запросов                                      */
  /*****************************************************************/
  "jsonrpc-queue": [
    {
      /* Это адаптер для workflow с jsonrpc интерфейсом. При переполнение очереди 
         возвращает JSON-RPC ошибку QueueOverflow */
      "name": "server-queue",
      "enabled": true,
      "suspend": false,
      "startup_priority": 0,
      "shutdown_priority": 0,
      /* Это workflow для входящие очереди */
      "workflow": "server-workflow",
      /* И еще раз отправляем на сбор статистики  */
      "target": "prefixdb-service1",

      /* Можно задать workflow для исходящей очереди. Имеет смысл только при тяжелых ответах на запрос 
         и/или ответ в прикладной области отправляется под мьютексом. В данном случае на время ответа не 
         повлияет но увеличит нагрузку на CPU  */
      "callback_queue": false,
      "callback_workflow": ""
    }
  ],

  /*****************************************************************/
  /* Сервис PrefixDB                                               */
  /*****************************************************************/
  "prefixdb-service": [
    /* Десериализует параметры запроса и осуществляет вызов метода прикладного объекта*/
    {
      "name": "prefixdb-service1",
      "enabled": true,
      "suspend": false,
      "startup_priority": 0,
      "shutdown_priority": 0,

      /* Только для сбора статы. Достаточно общего workflow ядра WFC*/
      "workflow": "", 
      /* Прикладной объект*/
      "target": "prefixdb1",
      /*  Пропускать не JSON-RPC запросы. Может использоваться если в прикладном объекте реализован 
       *  метод iinterface::perfom_io для произвольных сообщений. Обычно для этого открывают другой 
       *  порт, но если сервер соединен непосредственно с сервисом, то можно по одному порту  */
      "allow_non_jsonrpc": true,
      /* В большинстве случаев не нужно отслеживать подключение/отключение клиентов, а также делать 
       * встречные вызовы (с сервера к клиенту), поэтому отключаем реестр вызовов (автоматически отключается 
       * очередь ожидания ответов на запросы)*/
      "disable_handler_map": true,

      /* Следующие опции работают только при "disable_handler_map": false */
      /* Максимальное время ожидания ответа на встречный запрос */
      "call_lifetime_ms": 60000,
      /* Осуществлять проверку очереди при каждом запросе */
      "remove_everytime": true,
      /* Периодичность удаления устаревших запросов из очереди ожидания */
      "remove_outdated_ms": 0
    }
  ],

  /*****************************************************************/
  /* prefixdb                                                      */
  /*****************************************************************/
  "prefixdb": [
    {
      "name": "prefixdb1",
      "enabled": true,
      /* В suspend режиме отправляет пустой ответ. Может быть использован для отладки производительности.
       * (Если есть существенная разница в suspend и не-suspend то основные ресурсы уходят на прикладную логику) */
      "suspend": false,
      /* Должен запускаться после клиента мастера, иначе может не подцепиться репликация */
      "startup_priority": 0,
      "shutdown_priority": 0,
      /* Для таймеров слева и очереди отложенной записи */
      "workflow": "prefixdb-workflow",
      /* Сканирует папку о открывает БД префиксов иначе только при первом запросе */
      "preopen": true,
      /* Ограничение на количество ключей в одном запросе */
      "keys_per_req": 100,
      /* Максимальная длина ключа в запросе */
      "key_size_limit": 256,
      /* Максимальный размер значения в запросе */
      "value_size_limit": 10240,
      "prefix_size_limit": 256,
      /* Максимальная длина префикса в запросе */
      "max_prefixes": 128,
      /* Путь к БД префиксов */
      "path": "/monamour2/prefixdb/slave1",
      /* WAL можно хранить в другом месте ( например SSD ) */
      "wal_path": "",
      /* Путь куда будут перемещаться БД префиксов при вызове detach_prefix */
      "detach_path": "/monamour2/prefixdb/slave1_detach",
      /* максимальный размер хранимых json-объектов (не реализовано) */
      "packed_limit": 1000,
      /* максимальный размер хранимых json-массивов (не реализовано) */
      "array_limit": 1000,
      /* ограничение на количество возвращаемых ключей для range за один запрос  */
      "range_limit": 10000,
      /* Отложенная запись через очередь. Уменьшается время ответа на модифицирующие запросы 
       * если не нужен результат и не задан параметр sync в запросе. Внимание! Если не задан 
       * sync в запросе, то фактическая запись в базу может быть произведена позже, чем клиент 
       * получит ответ об успешной операции. Если в этот момент демон останавливается, то 
       * все запросы в очереди теряются 
       */
      "enable_delayed_write": true,
      /* Автоматическое восстановление при старте на поврежденной базе */
      "auto_repair": false,
      /* Завершить работу при ошибке открытия БД*/
      "abort_if_open_error": true,
      /* Проверять json в операциях типа package */
      "check_merge_operations": true,
      /* ini-конфиг для RocksDB */
      "ini": "./rocksdb.ini",
      /*"ini": "/usr/monamour/prefixdb/rocksdb.ini",*/

      /* Периодическое переуплотнение БД префиксов (может ускорить работу после удаления массива данных )*/
      "compact": {
        /* Запускать сразу после открытия(работает только с preopen=true и независимо от "enabled")*/
        "startup_compact": false,
        /* Вкл/выкл периодическое переуплотнение (не влияет на startup_compact) 
           Если не заданы start_time и period_s то раз в сутки с момента запуска
          */
        "enabled": false,
        /* Запускать в заданное время, например 03:00:00 */
        "start_time": "",
        /* Если не задано, то раз в сутки. Если не ноль и start_time="" то с заданой периодичностью с 
           момента запуска или начиная со времени start_time */
        "period_s": 0
      },

      /* Настройки слейва */
      "slave": {
        "enabled": true,
        /* Имя шлюза для мастера */
        "target": "master-gateway",
        /* Время запуска слейва (не знаю зачем может понадобится, просто есть )*/
        "start_time": "",
        /* Периодичность вычитывания изменений*/
        "pull_timeout_ms": 1000,
        /* Периодичность вычитывания списка префиксов */
        "query_prefixes_timeout_ms": 60000,
        /* Ограничение на количество изменений за один запрос */
        "log_limit_per_req": 1500,
        /* Допустимые потери при репликации (только для отладки! )*/
        "acceptable_loss_seq": 0,
        /* Величина отставания слейва от мастера, при которой идет запись в лог предупреждения */
        "wrn_log_diff_seq": 10000,
        /* Периодичность записи в лог предупреждение при отставании слейва */
        "wrn_log_timeout_ms": 1000,
        /* Периодичность записи в лог информации о процессе получения данных с мастера  */
        "seq_log_timeout_ms": 60000,
        /*устарело*/
        "enable_progress": false,
        /*устарело*/
        "expires_for_req": true
      },
      /* Настройка инкрементального бэкапа */
      "backup": {
        "enabled": true,
        /* Время первого бэкапа */
        "start_time": "",
        /* Интервал */
        "period_s": 600,
        /* Глубина (количество точек, с которых можно восстановиться ). Чем их больше тем больше размер */
        "depth": 12,
        /* Путь к файлу бэкапа */
        "path": "/monamour2/prefixdb/slave1_backup"
      },
      /* Архив бэкапов (просто копирует бэкап в указанное место )*/
      "archive": {
        "enabled": true,
        /* Раз в сутки в 5 утра */
        "start_time": "05:00:00",
        "period_s": 0,
        "path": "/monamour2/prefixdb/slave1_archive",
        /* Глубина бэкапа в архиве (количество точек восстановления)*/
        "depth": 1
      },
      /* Опции восстановления по умолчанию. Для запуска восстановления:
         # восстановление с текущего бэкапа в соответствии с настройками 
         ./prefixdb -C conf --instance-options="prefixdb1:restore"
         # восстановление с указанного бэкапа 
         ./prefixdb -C conf --instance-options="prefixdb1:restore=/monamour2/prefixdb/slave1_backup"
         # восстановление с указанной точки 
         ./prefixdb -C conf --instance-options="prefixdb1:pid=3:restore=/monamour2/prefixdb/slave1_backup"
        */
      "restore": {
        /* Запретить восстановление для данной конфигурации */
        "forbid": true,
        /* Точка восстановления по умолчанию */
        "backup_id": 0,
        /* Путь к бэкапу по умолчанию */
        "path": "/monamour2/prefixdb/slave1_backup"
      },
      /* Устарело */
      "stop_list": []
    }
  ],

  /*****************************************************************/
  /* Шлюз мастера PrefixDB                                         */
  /*****************************************************************/
  "prefixdb-gateway": [
    {
      "name": "master-gateway",
      "enabled": true,
      "suspend": false,
      "startup_priority": -700,
      "shutdown_priority": 700,
      "workflow": "",

      /* Куда отправлять исходящие запросы */
      "outgoing_target": "master-client",
      /* Инициирует подключение клиента client-tcp к серверу при старте*/
      "outgoing_reg": true,

      /* Цель для встречных входящих запросов (PrefixDB таких не делает ) */
      "incoming_target": "",
      "incoming_reg": false,
      
      /* Для шлюза в данном случае отключать нельзя */
      "disable_handler_map": false,

      /* Следующие опции работают только при "disable_handler_map": false */
      /* Максимальное время ожидания ответа на встречный запрос */
      "call_lifetime_ms": 60000,
      /* Осуществлять проверку очереди при каждом запросе */
      "remove_everytime": true,
      /* Периодичность удаления устаревших запросов из очереди ожидания */
      "remove_outdated_ms": 1000
    }
  ],

  /*****************************************************************/
  /* TCP клиент                                                    */
  /*****************************************************************/
  "client-tcp": [
    /* Подключение к PrefixDB мастеру */
    {
      "name": "master-client",
      "enabled": true,
      /* В suspend режиме эмулирует эхо-сервер */
      "suspend": false,
      "startup_priority": -800,
      "shutdown_priority": 800,

      "workflow": "",
      "addr": "cdaemon17",
      "port": "23502",
      /* Количество коннектов на поток (запросы распределяются по очереди по коннектам )*/
      "connect_count": 1,
      /* Количество потоков (запросы распределяются по очереди сначала по потоками, потом по коннектам )*/
      "threads": 1,
      /* Асинхронный коннект*/
      "async_connect": true,
      /* Таймаут реконнекта, если сервер отвалился */
      "reconnect_timeout_ms": 1000,
      
      /* Такие же настройки как и у сервера */
      "connection": {
        "reader": {
          "sep": "\r\n",
          "bufsize": 4096,
          "maxbuf": 8192,
          "minbuf": 0,
          "trimsep": true
        },
        "writer": {
          "sep": "\r\n",
          "bufsize": 8192,
          "maxbuf": 8192,
          "minbuf": 0,
          "first_as_is": true
        }
      }
    }
  ]
}
