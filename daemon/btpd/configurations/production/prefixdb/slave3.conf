{
  /* Разбирает параметры командной строки и запускает демон. Опций не имеет.*/
  "startup": {},

  /*****************************************************************/
  /* Читает и валидирует файл конфигурации.                        */
  /*****************************************************************/
  "config": {
    "enabled": true,
    /* Разрешить перечитывать конфигурацию по сигналу SIGHUP */
    "reload_sighup": false,
    /* Проверять на изменения конфигурацию и перечитывать ее. 0 - выкл.*/
    "reload_changed_ms": 0
    /* Примечание: Динамическое переконфигурирование работает крайне нестабильно, поэтому использовать в бою нельзя */
  },

  /*****************************************************************/
  /* Ядро WFC. Реализует алгоритмы инициализации и запуска системы */
  /*****************************************************************/
  "core": {
    /* Периодичность выполнения задач ядра (проверка на переинициализации при изменении конфигурации или флаг выхода)*/
    "core_timeout_ms": 1000,
    /* Запуск пользовательских задач в основном потоке демона */
    "idle_timeout_ms": 1000,
    /* Ограничение оперативной памяти */
    "rlimit_as_mb": 0,
    /* Зарезервировано (пока не работает)*/
    "enable_callback_check": true,

    /*Настройка workflow ядра */
    "core-workflow": {
      /* Число рабочих потоков. 0 - в основном потоке демона */
      "threads": 2,
      /* Использовать boost::io_service */
      "use_io_service": true

      /* Примечание: workflow - это очередь задач и пул потоков, который ее разгребает.
       *             Также поддерживает таймеры и реквестеры. Каждый прикладной объект 
       *             имеет доступ к workflow, если он не указан, то используется этот
       *             workflow ядра. См. также раздел "workflow"
       */
    },
    /* список ядер cpu для потоков WFC (потоки workflow, серверов и клиентов, а также пользовательских зарегистрированных потоков) */
    "cpu": [ ],
    /* список ядер cpu для всех остальных потоков */
    "unreg-cpu": []
  },

    /*****************************************************************/
  /* Система логирования                                           */
  /*****************************************************************/
  "logger": {
    /* При отключении модуля логирования сообщения выводятся в clog без форматирования */
    "enabled": true,
    /* Приоритет запуска. Должен быть минимальным в конфигурации, чтобы логирование запускалось раньше всех */
    "startup_priority": -1000,
    /* Аналогично, останов логирования должен происходить в последнюю очередь */
    "shutdown_priority": 1000,
    /* Отображать миллисекунды в логах */
    "milliseconds": true,
    /* Ограничение длинны лог-файла в байтах */
    "limit": 10000000,
    /* Стандартный вывод в режиме не-демона: cerr, cout или clog */
    "stdout": "clog",
    /* Путь для файла(ов) логов. В сингл режиме просто добавляется ".log" */
    "path": "/logs/prefixdb-slave3",
    /* Разрешить писать в syslog (имя) */
    "syslog": "",
    /* Список запрещенных логов или типов логов в нижнем регистре */
    "deny": ["debug"],
    /* Если false то каждый лог пишется в отдельный файл, например */
    "single": true,
    "custom": {
      /* Карта кастомных настроек для каждого лога, например можно лог stat писать в отдельный файл */
      "stat":{
        "path": "/logs/prefixdb-slave3-stat.log",
        "milliseconds": true
      }
    }
  },

  /*****************************************************************/
  /* Рабочие процессы                                              */
  /*****************************************************************/
  "workflow": [
    {
      /* workflow обработки jsonrpc-запросов (см. jsonrpc-queue) */
      "name": "server-workflow",
      "enabled": true,
      /* запускаем раньше, чем server-tcp, чтобы очередь не разбухала */
      "startup_priority": -900,
      "shutdown_priority": 900,

      /* сбор статы */
      "statistics": {
        /* По умолчанию выключена, включаем */
        "disabled": false,
        /* Имя агрегатора статистики (см. statistics-aggregator)*/
        "target": "stat1",
        /* Периодичность отправки статы*/
        "interval_ms": 1000,
        /* Имя для длины очереди */
        "queue": ".queue",
        /* Количество отброшеных задач с момента отправки пред. статы */
        "dropped": ".dropped",
        /* Стата по потокам (для каждого .thread0, .thread1 ... и общий .thread )
         * На графике count - количество выполненных задач, перцентили - время выполнения 
         * задач включая ожидание (если задачи поступают раз в сек, то и время выполнения ~сек)
         */
        "thread": ".thread"
      },

      /* Максимальный размер очереди (для jsonrpc в штатном режиме 1-2, разрастание очереди свидетельствует о том, что сервер не справляется) 
       * При запуске возможен кратковременное разрастание когда одновременно приходит множество запросов */
      "maxsize": 100,
      /* Размер очереди при котором происходить предупреждение в лог */
      "wrnsize": 10,
      /* Периодичность записи предупреждения в лог (пока размер превосходит wrnsize) */
      "show_wrn_ms": 1000,
      /* Число рабочих потоков. 0 - в основном потоке демона */
      "threads": 1,
      "use_io_service": true,
      /* Обрабатывать задачи с задержкой. Например для 50 мс, означает что время ответа на запрос будет не менее 50мс. 
       * Можно открыть отдельный порт для кроновых скриптов и настроить очередь с задержкой, чтобы не сильно "валили" запросами */
      "post_delay_ms": 0,
      /* Ограничение по количеству обрабатываем задач ОДНИМ потоком. */
      "rate_limit": 0,
      /* Список выделенных ядер CPU для потоков этого workflow. Если пуст, то настройки ядра  WFC */
      "cpu": []
    },
    
    /* Для prefixdb*/
    {
      "name": "prefixdb-workflow",
      "enabled": true,
      "startup_priority": -900,
      "shutdown_priority": 900,

      "statistics": {
        "disabled": false,
        "target": "stat1",
        "interval_ms": 1000,
        "queue": ".queue",
        "dropped": ".dropped",
        "thread": ".thread"
      },

      "maxsize": 1000,
      "wrnsize": 100,
      "show_wrn_ms": 1000,
      "threads": 1,
      "use_io_service": true,
      "post_delay_ms": 0,
      "rate_limit": 0,
      "cpu": []
    }
  ],  

  /*****************************************************************/
  /* Агрегатор статистики демона                                  */
  /*****************************************************************/
  "statistics-aggregator": [
    /* Агрегирует статистику и отправляет в btp и/или в лог. */
    {
      "name": "stat1",
      "enabled": true,
      /* В режиме suspend принимает данные, но ничего не делает */
      "suspend": false,
      /* workflow не указываем, т.к. отдельный workflow не нужен, достаточно workflow ядра*/
      "workflow": "",
      "statistics": {
        "disabled": false,
        /* Шаг агрегации. Лучше делать меньше 5 сек, чтобы графики не "скакали" в бтп */
        "step_ms": 1000,
        /* Ограничение массива значений для одного счетчика на шаг агрегации. Если за время 
           step_ms накопится больше, то начинается "прореживание" данных  */
        "limit": 4096,
        /* Уровни прореживания. limit*levels мак. кол-во собираемых значений до прореживания, остальные отбрасываются */
        "levels": 16,
        /* Размер прореженного массива сырых данных, который отправляем бтп. */
        "reduced_size": 128,
        /* Размер пула буферов ( один буфер limit*8 байт ) */
        "pool": 0,
        
        /* Префиксы для счетчиков отправляемых в BTP. */
        "prefixes": [
          /* Общий счетчик для всех демонов PrefixDB */
          "service~~daemon:PrefixDB-Slave~~",
          /* Общий счетчик для всех демонов PrefixDB на запущенных на хосте cdaemon16 */
          "service~~daemon:PrefixDB-Slave~~cdaemon16~~",
          /* Счетчик для конкретного экземпляра демона PrefixDB */
          "script~~daemon:PrefixDB-Slave3~~daemon:PrefixDB-Slave~~"
        ]
      },
      /* Игнорирование входящих значений при запуске заданное время, чтобы не "портить" графики большими всплесками */
      "btp_delay_ms": 5000,
      /* Шлюз БТП. Данные уже агрегированы, поэтому сразу отправляем на 5-сек демон*/
      "btp_target": "btp-gateway",
      /* Имя лога для дублирования статы ("" - чтобы не писать в лог) */
      /*"log": "stat",*/
      /* Периодичность отправки данных в БТП и записи в лог */
      "timeout_ms": 1000,
      /* Формат данных в логе: perseconds(в запр. сек), seconds, milliseconds, microseconds, nanoseconds, hide*/
      "log_metric": "microseconds"
    }
  ],

  /*****************************************************************/
  /* Системная статистика демона                                   */
  /*****************************************************************/
  "system-statistics": [
    {
      "name": "system-statistics1",
      "enabled": true,
      "suspend": false,
      "startup_priority": 0,
      "shutdown_priority": 0,
      "workflow": "",
      "statistics": {
        "disabled": false,
        /* Имя агрегатора статистики */
        "target": "stat1",
        /* Пока вшиты метрики rss (resident set size), utime, stime, можно задать для них префикс. */
        "prefix": "",
        /* Интервал сбора */
        "interval_ms": 1000
      }
    }
  ],

  /*****************************************************************/
  /* TCP сервер                                                    */
  /*****************************************************************/
  "server-tcp": [
    {
      "name": "server-tcp",
      "enabled": true,
      /* В режиме suspend работает как эхо-сервер */
      "suspend": false,
      /* Порты открываем в последнюю очередь */
      "startup_priority": 1000,
      /* А закрываем в первую, чтобы входящий поток запросов не мешал корректно завершить работу */
      "shutdown_priority": -1000,
      /* Здесь используется свой пул запросов, workflow только для таймеров, можно использовать workflow ядра */
      "workflow": "",
      /* Статистика по потокам аналогично workflow ("thread": ".thread") имена пока вшиты */
      "statistics": {
        "disabled": false,
        /* Имя агрегатора статистики */
        "target": "stat1"
      },
      /* Следующий по цепочке компонент сбора io-статистики, для мониторинга входящего трафика */
      "target": "io-statistics1",
      /* Включает поддержку keep-alive */
      "keep-alive": true,
      /* Список выделенных ядер CPU для потоков этого сервера. Если пуст, то настройки ядра WFC */
      "cpu": [],

      /* Количество потоков.
       * В каждом потоке "висит" акцептор и в нем же обрабатываются сокеты, которые принял акцептор.
       * Если используется входящая очередь ( io-queue из пакета wfc_io или jsonrpc-queue из пакета wfc_jsonrpc)
       * то нет смысла запускать большое количество потоков, с парсингом и сборкой по простому разделителю сервер 
       * справляется достаточно эффективно.
       * Если время ответа от прикладной логики стабильно мало (более 100000 запросов в сек. ( или менее 10 мкс) ) 
       * то имеет смысл отключить очереди и увеличить количество потоков сервера. На общее время ответа это не сильно 
       * повлияет, но заметно снизит нагрузку на CPU.
       * Архитектура "один слушатель" + "пул воркеров" не поддерживается, т.к. по производительности и ресурсам 
       * она не превосходит схему сервер+очередь, но имеет те же недостатки варианта сервер без очереди (при тяжелом 
       * запросе остальные сокеты потока вынуждены ждать 
       */
      "threads": 1,
      /*ip адрес или имя хоста*/
      "addr": "0.0.0.0",
      "port": "23520",
      /* Очередь входящих запросов на соединение (linux) */
      "backlog": 1024,
      /* Ограничение на количество одновременных подключений (сервер)*/
      "max_connections": 0,

      /* настройки для коннектов */
      "connection": {
        /* 'Читатель' из сокета */
        "reader": {
          /* разделитель входного потока*/
          "sep": "\r\n",
          /* Буфер для операции чтения. Можно уменьшить, если все запросы короткие, 
           * но нет смысла увеличивать больше 8-32Кб даже для больших запросов или 
           * потока сообщений по одному подключению */
          "bufsize": 4096,
          /* Максимальный размер чанка входящего буфера, после которого происходит разделение на массивы размером не более bufsize */
          "maxbuf": 8192,
          /* Если при разделении, последний буфер меньше minbuf то он сливается с предпоследним, при условии, что не будет превышен maxbuf*/ 
          "minbuf": 0,
          /* Удалять разделитель из сообщения*/
          "trimsep": true
        },
        /* 'Писатель' в сокет */
        "writer": {
          /* Добавляет разделитель в конец сообщения */
          "sep": "\r\n",
          /* Буфер для операции записи. */
          "bufsize": 8192,
          /* Максимальный размер чанка исходящего буфера, после которого происходит разделение на массивы размером не более bufsize */
          "maxbuf": 8192,
          /* Если при разделении, последний буфер меньше minbuf то он сливается с предпоследним, при условии, что не будет превышен maxbuf*/ 
          "minbuf": 0,
          /* Если исходящий буфер пуст, а размер сообщения превышает maxbuf, то делается попытка записать сообщение целиком 
             и только потом остаток сообщения разбивается на чанки размером bufsize. Эффективно работает на сообщениях до 1Мб, если больше
             то эффективнее предварительно разбить на массивы 16-32Кб   */
          "first_as_is": true
        }
      }
    }
  ],
  
  /*****************************************************************/
  /* Статистика входящего/исходящего трафика                       */
  /*****************************************************************/
  "io-statistics": [
    {
      "name": "io-statistics1",
      "enabled": true,
      "suspend": false,
      "statistics": {
        "disabled": false,
        "target": "stat1"
      },
      /* Далее собираем jsonrpc-статистику */
      "target": "jsonrpc-statistics1",
      /* Интервал отправки в агрегатор статистики */
      "interval_ms": 100,
      /* Имя для количества одновременных коннектов  */
      "io_name": "connections",
      /* Время обработки одного сообщения (включая прохождение по очередям) */
      "time_name": "time",
      /* Входящий трафик (в count- общий трафик, в перцентилях размеры пакетов */
      "read_name": "read_size",
      /* Исходящий трафик (в count- общий трафик, в перцентилях размеры пакетов */
      "write_name": "write_size"
    }
  ],

  /*****************************************************************/
  /* Статистика jsonrpc-запросов                                   */
  /*****************************************************************/
  "jsonrpc-statistics": [
    {
      /* Первый компонент сбора статистики с учетом прохождения очередей */
      "name": "jsonrpc-statistics1",
      "enabled": true,
      "suspend": false,
      "statistics": {
        "disabled": false,
        "target": "stat1"
      },
      /* Далее отправляем запрос в очередь. Таким образом время выполнения метода с учетом прохождения очереди*/
      "target": "server-queue",
      /* Включить статистику размеров результатов вызова*/
      "enable_write_size": true,
      /* Включить стату по ошибкам */
      "enable_error_stat": true,
      /* суффикс для времен (пример: req:classify_simple.time) */
      "time_suffix": ".time",
      /* суффикс для размера входящих запросов  */
      "read_size_suffix": ".rsize",
      /* суффикс для размера исходящих запросов  */
      "write_size_suffix": ".wsize",
      /* Префикс для запросов (пример: req:classify_simple.time)*/
      "request_prefix": "req:",
      /* Префикс для уведомлений */
      "notify_prefix": "ntf:",
      
      /* Для прочего валидного jsonrpc, но мусора */
      "other_time": "other:time",
      "other_read_size": "other:rsize",
      "other_write_size": "other:wsize"
    },

    {
      /* Второй компонент сбора статистики без учета прохождения очередей (непосредственно вызов) */
      "name": "jsonrpc-statistics2",
      "enabled": true,
      "suspend": false,
      "statistics": {
        "disabled": false,
        "target": "stat1"
      },
      /* Далее отправляем запрос десериализацию и вызов конкретного метода прикладного объекта*/
      "target": "prefixdb-service1",
      "enable_write_size": true,
      "enable_error_stat": true,
      "time_suffix": ".time",
      "read_size_suffix": ".rsize",
      "write_size_suffix": ".wsize",
      "request_prefix": "req:prefixdb:",
      "notify_prefix": "ntf:prefixdb:",
      "other_time": "other:prefixdb.time",
      "other_read_size": "other:prefixdb.rsize",
      "other_write_size": "other:prefixdb.wsize"
    },

    {
      /* Статистика запросов к мастеру  */
      "name": "jsonrpc-statistics3",
      "enabled": true,
      "suspend": false,
      "statistics": {
        "disabled": false,
        "target": "stat1"
      },

      "target": "master-client",
      "enable_write_size": true,
      "enable_error_stat": true,
      "time_suffix": ".time",
      "read_size_suffix": ".rsize",
      "write_size_suffix": ".wsize",
      "request_prefix": "req:master:",
      "notify_prefix": "ntf:master:",
      "other_time": "other:master.time",
      "other_read_size": "other:master.rsize",
      "other_write_size": "other:master.wsize"
    }
  ],

  /*****************************************************************/
  /* Очередь jsonrpc-запросов                                      */
  /*****************************************************************/
  "jsonrpc-queue": [
    {
      /* Это адаптер для workflow с jsonrpc интерфейсом. При переполнение очереди 
         возвращает JSON-RPC ошибку QueueOverflow */
      "name": "server-queue",
      "enabled": true,
      "suspend": false,
      "startup_priority": 0,
      "shutdown_priority": 0,
      /* Это workflow для входящие очереди */
      "workflow": "server-workflow",
      /* И еще раз отправляем на сбор статистики  */
      "target": "jsonrpc-statistics2",

      /* Можно задать workflow для исходящей очереди. Имеет смысл только при тяжелых ответах на запрос 
         и/или ответ в прикладной области отправляется под мьютексом. В данном случае на время ответа не 
         повлияет но увеличит нагрузку на CPU  */
      "callback_queue": false,
      "callback_workflow": ""
    }
  ],

  /*****************************************************************/
  /* Сервис PrefixDB                                               */
  /*****************************************************************/
  "prefixdb-service": [
    /* Десериализует параметры запроса и осуществляет вызов метода прикладного объекта*/
    {
      "name": "prefixdb-service1",
      "enabled": true,
      "suspend": false,
      "startup_priority": 0,
      "shutdown_priority": 0,
      /* Только для сбора статы. Достаточно общего workflow ядра WFC*/
      "workflow": "", 

      "statistics": {
        /* Статистику выключаем т.к. disable_handler_map реестр не запросов ведется */
        "disabled": true,
        "target": "stat1",
        /* Периодичность отправки */
        "interval_ms": 1000,
        /* Размер реестра входящих обработчиков */
        "handler_map": ".handler_map",
        /* Очередь ожидания ответов на запросы */
        "result_queue": ".result_queue"
      },

      /* Прикладной объект*/
      "target": "prefixdb1",
      /*  Пропускать не JSON-RPC запросы. Может использоваться если в прикладном объекте реализован 
       *  метод iinterface::perfom_io для произвольных сообщений. Обычно для этого открывают другой 
       *  порт, но если сервер соединен непосредственно с сервисом, то можно по одному порту  */
      "allow_non_jsonrpc": true,
      /* В большинстве случаев не нужно отслеживать подключение/отключение клиентов, а также делать 
       * встречные вызовы (с сервера к клиенту), поэтому отключаем реестр вызовов (автоматически отключается 
       * очередь ожидания ответов на запросы)*/
      "disable_handler_map": true,

      /* Следующие опции работают только при "disable_handler_map": false */
      /* Максимальное время ожидания ответа на встречный запрос */
      "call_lifetime_ms": 60000,
      /* Осуществлять проверку очереди при каждом запросе */
      "remove_everytime": true,
      /* Периодичность удаления устаревших запросов из очереди ожидания */
      "remove_outdated_ms": 0
    }
  ],

  /*****************************************************************/
  /* prefixdb                                                      */
  /*****************************************************************/
  "prefixdb": [
    {
      "name": "prefixdb1",
      "enabled": true,
      /* В suspend режиме отправляет пустой ответ. Может быть использован для отладки производительности.
       * (Если есть существенная разница в suspend и не-suspend то основные ресурсы уходят на прикладную логику) */
      "suspend": false,
      /* Должен запускаться после клиента мастера, иначе может не подцепиться репликация */
      "startup_priority": 0,
      "shutdown_priority": 0,
      /* Для таймеров слева и очереди отложенной записи */
      "workflow": "prefixdb-workflow",
      /* Сканирует папку о открывает БД префиксов иначе только при первом запросе */
      "preopen": true,
      /* Ограничение на количество ключей в одном запросе */
      "keys_per_req": 100,
      /* Максимальная длина ключа в запросе */
      "key_size_limit": 256,
      /* Максимальный размер значения в запросе */
      "value_size_limit": 10240,
      "prefix_size_limit": 256,
      /* Максимальная длина префикса в запросе */
      "max_prefixes": 128,
      /* Путь к БД префиксов */
      "path": "/monamour/prefixdb/slave3",
      /* WAL можно хранить в другом месте ( например SSD ) */
      "wal_path": "",
      /* Путь куда будут перемещаться БД префиксов при вызове detach_prefix */
      "detach_path": "/monamour/prefixdb/slave3_detach",
      /* максимальный размер хранимых json-объектов (не реализовано) */
      "packed_limit": 1000,
      /* максимальный размер хранимых json-массивов (не реализовано) */
      "array_limit": 1000,
      /* ограничение на количество возвращаемых ключей для range за один запрос  */
      "range_limit": 10000,
      /* Отложенная запись через очередь. Уменьшается время ответа на модифицирующие запросы 
       * если не нужен результат и не задан параметр sync в запросе. Внимание! Если не задан 
       * sync в запросе, то фактическая запись в базу может быть произведена позже, чем клиент 
       * получит ответ об успешной операции. Если в этот момент демон останавливается, то 
       * все запросы в очереди теряются 
       */
      "enable_delayed_write": true,
      /* Автоматическое восстановление при старте на поврежденной базе */
      "auto_repair": false,
      /* Завершить работу при ошибке открытия БД*/
      "abort_if_open_error": true,
      /* Проверять json в операциях типа package */
      "check_merge_operations": true,
      /* ini-конфиг для RocksDB */
      "ini": "./rocksdb.ini",
      /*"ini": "/usr/monamour/prefixdb/rocksdb.ini",*/

      /* Периодическое переуплотнение БД префиксов (может ускорить работу после удаления массива данных )*/
      "compact": {
        /* Запускать сразу после открытия(работает только с preopen=true и независимо от "enabled")*/
        "startup_compact": false,
        /* Вкл/выкл периодическое переуплотнение (не влияет на startup_compact) 
           Если не заданы start_time и period_s то раз в сутки с момента запуска
          */
        "enabled": false,
        /* Запускать в заданное время, например 03:00:00 */
        "start_time": "",
        /* Если не задано, то раз в сутки. Если не ноль и start_time="" то с заданой периодичностью с 
           момента запуска или начиная со времени start_time */
        "period_s": 0
      },

      /* Настройки слейва */
      "slave": {
        "enabled": true,
        /* Имя шлюза для мастера */
        "target": "master-gateway",
        /* Время запуска слейва (не знаю зачем может понадобится, просто есть )*/
        "start_time": "",
        /* Периодичность вычитывания изменений*/
        "pull_timeout_ms": 1000,
        /* Периодичность вычитывания списка префиксов */
        "query_prefixes_timeout_ms": 60000,
        /* Ограничение на количество изменений за один запрос */
        "log_limit_per_req": 1500,
        /* Допустимые потери при репликации (только для отладки! )*/
        "acceptable_loss_seq": 0,
        /* Величина отставания слейва от мастера, при которой идет запись в лог предупреждения */
        "wrn_log_diff_seq": 10000,
        /* Периодичность записи в лог предупреждение при отставании слейва */
        "wrn_log_timeout_ms": 1000,
        /* Периодичность записи в лог информации о процессе получения данных с мастера  */
        "seq_log_timeout_ms": 60000,
        /*устарело*/
        "enable_progress": false,
        /*устарело*/
        "expires_for_req": true
      },
      /* Настройка инкрементального бэкапа */
      "backup": {
        "enabled": true,
        /* Время первого бэкапа */
        "start_time": "",
        /* Интервал */
        "period_s": 600,
        /* Глубина (количество точек, с которых можно восстановиться ). Чем их больше тем больше размер */
        "depth": 12,
        /* Путь к файлу бэкапа */
        "path": "/monamour/prefixdb/slave3_backup"
      },
      /* Архив бэкапов (просто копирует бэкап в указанное место )*/
      "archive": {
        "enabled": true,
        /* Раз в сутки в 5 утра */
        "start_time": "05:00:00",
        "period_s": 0,
        "path": "/monamour/prefixdb/slave3_archive",
        /* Глубина бэкапа в архиве (количество точек восстановления)*/
        "depth": 1
      },
      /* Опции восстановления по умолчанию. Для запуска восстановления:
         # восстановление с текущего бэкапа в соответствии с настройками 
         ./prefixdb -C conf --instance-options="prefixdb1:restore"
         # восстановление с указанного бэкапа 
         ./prefixdb -C conf --instance-options="prefixdb1:restore=/monamour/prefixdb/slave3_backup"
         # восстановление с указанной точки 
         ./prefixdb -C conf --instance-options="prefixdb1:pid=3:restore=/monamour/prefixdb/slave3_backup"
        */
      "restore": {
        /* Запретить восстановление для данной конфигурации */
        "forbid": true,
        /* Точка восстановления по умолчанию */
        "backup_id": 0,
        /* Путь к бэкапу по умолчанию */
        "path": "/monamour/prefixdb/slave3_backup"
      },
      /* Устарело */
      "stop_list": []
    }
  ],

  /*****************************************************************/
  /* Шлюз мастера PrefixDB                                         */
  /*****************************************************************/
  "prefixdb-gateway": [
    {
      "name": "master-gateway",
      "enabled": true,
      "suspend": false,
      "startup_priority": -700,
      "shutdown_priority": 700,
      "workflow": "",

      /* Статистику включаем, т.к. используем очередь ожидания результатов на запрос. По ней можем отследить, что мастер втупил */
      "statistics": {
        "disabled": false,
        "target": "stat1",
        "interval_ms": 1000,
        "handler_map": ".handler_map",
        "result_queue": ".result_queue "
      },

      /* Куда отправлять исходящие запросы */
      "outgoing_target": "master-client",
      /* Инициирует подключение клиента client-tcp к серверу при старте*/
      "outgoing_reg": true,

      /* Цель для встречных входящих запросов (PrefixDB таких не делает ) */
      "incoming_target": "",
      "incoming_reg": false,
      
      /* Для шлюза в данном случае отключать нельзя */
      "disable_handler_map": false,

      /* Следующие опции работают только при "disable_handler_map": false */
      /* Максимальное время ожидания ответа на встречный запрос */
      "call_lifetime_ms": 60000,
      /* Осуществлять проверку очереди при каждом запросе */
      "remove_everytime": true,
      /* Периодичность удаления устаревших запросов из очереди ожидания */
      "remove_outdated_ms": 1000
    }
  ],

  /*****************************************************************/
  /* Шлюз BTP                                                      */
  /*****************************************************************/
  "btp-gateway": [
    /* Реализует API btp и преобразует вызовы в jsonrpc запросы которые отправляет на сервер через client-tcp
     * Основные настройки такие же как и для сервисов
     */
    {
      "name": "btp-gateway",
      "enabled": true,
      "suspend": false,
      "startup_priority": -700,
      "shutdown_priority": 700,
      "workflow": "",

      /* Статистику включаем, т.к. используем очередь ожидания результатов на запрос. По ней можем отследить, что бтп втупил */
      "statistics": {
        "disabled": false,
        "target": "stat1",
        "interval_ms": 1000,
        "handler_map": ".handler_map",
        "result_queue": ".result_queue "
      },

      /* Куда отправлять исходящие запросы */
      "outgoing_target": "btp-client",
      /* Инициирует подключение клиента client-tcp к серверу при старте*/
      "outgoing_reg": true,

      /* Цель для встречных входящих запросов (БТП таких не делает ) */
      "incoming_target": "",
      "incoming_reg": false,
      /* Для шлюза в данном случае отключать нельзя */
      "disable_handler_map": false,

      /* Следующие опции работают только при "disable_handler_map": false */
      /* Максимальное время ожидания ответа на встречный запрос */
      "call_lifetime_ms": 60000,
      /* Осуществлять проверку очереди при каждом запросе */
      "remove_everytime": true,
      /* Периодичность удаления устаревших запросов из очереди ожидания */
      "remove_outdated_ms": 1000
    }
  ],
  
  /*****************************************************************/
  /* TCP клиент                                                    */
  /*****************************************************************/
  "client-tcp": [
    /* Подключение к PrefixDB мастеру */
    {
      "name": "master-client",
      "enabled": true,
      /* В suspend режиме эмулирует эхо-сервер */
      "suspend": false,
      "startup_priority": -800,
      "shutdown_priority": 800,

      "workflow": "",
      "addr": "cdaemon25",
      "port": "23512",
      /* Количество коннектов на поток (запросы распределяются по очереди по коннектам )*/
      "connect_count": 1,
      /* Количество потоков (запросы распределяются по очереди сначала по потоками, потом по коннектам )*/
      "threads": 1,
      /* Асинхронный коннект*/
      "async_connect": true,
      /* Таймаут реконнекта, если сервер отвалился */
      "reconnect_timeout_ms": 1000,
      
      /* Такие же настройки как и у сервера */
      "connection": {
        "reader": {
          "sep": "\r\n",
          "bufsize": 4096,
          "maxbuf": 8192,
          "minbuf": 0,
          "trimsep": true
        },
        "writer": {
          "sep": "\r\n",
          "bufsize": 8192,
          "maxbuf": 8192,
          "minbuf": 0,
          "first_as_is": true
        }
      }
    },
    /* Подключение к BTP */
    {
      "name": "btp-client",
      "enabled": true,
      "suspend": false,
      "startup_priority": -500,
      "shutdown_priority": 500,
      
      "addr": "cdaemon14",
      "port": "37100",
      "threads": 1,
      "async_connect": false,
      "reconnect_timeout_ms": 1000
    }
  ]
}
